{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8ddb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all important module\n",
    "import selenium\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b2853",
   "metadata": {},
   "source": [
    "### Q1 https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b2f2d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Search Title: Guitar\n"
     ]
    }
   ],
   "source": [
    "value = input('Enter your Search Title: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07428db2",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "726b6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Google Images\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "# Find the search box\n",
    "search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "\n",
    "# Search for guitar images\n",
    "search_box.send_keys(value)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# initial all the list to store the product details\n",
    "product_url = []\n",
    "brand_list = []\n",
    "product_name = []\n",
    "price_list = []\n",
    "return_exchange_list = []\n",
    "expected_delivery = []\n",
    "availability_list = []\n",
    "\n",
    "for page in range(0, 3):\n",
    "    # fetch the product url\n",
    "    urls = driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]//a')\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # storing the url in list\n",
    "            product_url.append(url.get_attribute('href'))\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            product_url.append('-')\n",
    "    driver.find_element(By.XPATH, '//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "#     sleep(5)\n",
    "\n",
    "for i in product_url:\n",
    "    individual_page = driver.get(i)\n",
    "    try:    \n",
    "        # storing the name in list\n",
    "        name = driver.find_element(By.ID, 'productTitle')\n",
    "#         sleep(2)\n",
    "        product_name.append(name.text)\n",
    "\n",
    "        # storing the brand name in list\n",
    "        brand_name = driver.find_element(By.XPATH, '//tr[@class=\"a-spacing-small po-brand\"]//span[@class=\"a-size-base po-break-word\"]').text\n",
    "#         sleep(2)\n",
    "        brand_list.append(brand_name)\n",
    "\n",
    "        # storing the return date in list\n",
    "        return_exchange = driver.find_element(By.XPATH, '//*[@id=\"RETURNS_POLICY\"]/span/div[2]/span')\n",
    "#         sleep(2)\n",
    "        return_exchange_list.append(return_exchange.text)\n",
    "\n",
    "        # Try to find the price element\n",
    "        price_element = driver.find_element(By.XPATH, '//span[@class=\"a-price aok-align-center\"]')\n",
    "#         sleep(2)\n",
    "        \n",
    "        # If found, append its text to the list\n",
    "        price_list.append(price_element.text)\n",
    "\n",
    "        # Try to find the element\n",
    "        expected_date_element = driver.find_element(By.XPATH, '//*[@id=\"mir-layout-DELIVERY_BLOCK-slot-PRIMARY_DELIVERY_MESSAGE_LARGE\"]/span/span')\n",
    "#         sleep(2)\n",
    "        # If found, append its text to the list\n",
    "        expected_delivery.append(expected_date_element.text)\n",
    "        \n",
    "        # storing the availability of product in list\n",
    "        availability = driver.find_element(By.ID, 'availability')\n",
    "#         sleep(2)\n",
    "        availability_list.append(availability.text)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        # If not found, append '-' to the list\n",
    "        return_exchange_list.append('-')\n",
    "\n",
    "        # If not found, append '-' to the list\n",
    "        price_list.append('-')\n",
    "\n",
    "        # If not found, append '-' to the list\n",
    "        expected_delivery.append('-')\n",
    "\n",
    "        # If not found, append '-' to the list\n",
    "        availability_list.append('-')\n",
    "        \n",
    "        # If not found, append '-' to the list\n",
    "        brand_list.append('-')\n",
    "        \n",
    "\n",
    "# Get the maximum length among the lists\n",
    "max_length = max(len(lst) for lst in [product_url, product_name, return_exchange_list, brand_list, price_list, expected_delivery, availability_list])\n",
    "\n",
    "# Pad shorter lists with '-'\n",
    "product_url = product_url + ['-'] * (max_length - len(product_url))\n",
    "product_name = product_name + ['-'] * (max_length - len(product_name))\n",
    "return_exchange_list = return_exchange_list + ['-'] * (max_length - len(return_exchange_list))\n",
    "brand_list = brand_list + ['-'] * (max_length - len(brand_list))\n",
    "price_list = price_list + ['-'] * (max_length - len(price_list))\n",
    "expected_delivery = expected_delivery + ['-'] * (max_length - len(expected_delivery))\n",
    "availability_list = availability_list + ['-'] * (max_length - len(availability_list))\n",
    "\n",
    "\n",
    "# creating dic\n",
    "data = {'Product URL': product_url, 'Product Name' : product_name, 'Return/Exchange' : return_exchange_list,\n",
    "        'Brand Name' : brand_list, 'Price' : price_list, 'Expected Delivary Date' : expected_delivery, \n",
    "        'Availability' : availability_list }\n",
    "\n",
    "\n",
    "# creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('amazone_product_detials.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94930c0c",
   "metadata": {},
   "source": [
    "### Q3 https://images.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5927ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open Google Images\n",
    "    driver.get('https://images.google.com/')\n",
    "    \n",
    "    # Find the search box\n",
    "    search_box = driver.find_element(By.NAME, 'q')\n",
    "    \n",
    "    # Search for guitar images\n",
    "    search_box.send_keys('guitar')\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    # Wait for the images to load\n",
    "    sleep(2)\n",
    "    \n",
    "    # Scroll down to load more images\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(2)\n",
    "    \n",
    "    # Fetch image elements\n",
    "    image_elements = driver.find_elements(By.XPATH, '//img[@class=\"YQ4gaf\"]')\n",
    "    \n",
    "    # Prepare to download images\n",
    "    os.makedirs('guitar_images', exist_ok=True)\n",
    "    img_count = 0\n",
    "    \n",
    "    for img_elem in image_elements:\n",
    "        if img_count >= 10:\n",
    "            break\n",
    "        try:\n",
    "            img_url = img_elem.get_attribute('src')\n",
    "            if img_url is not None and 'http' in img_url:\n",
    "                img_data = requests.get(img_url).content\n",
    "                with open(f'guitar_images/guitar_{img_count + 1}.jpg', 'wb') as handler:\n",
    "                    handler.write(img_data)\n",
    "                img_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download image {img_count + 1}: {e}\")\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126e521",
   "metadata": {},
   "source": [
    "### Q4 https://www.flipkart.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input value\n",
    "value = input('Enter your Search Title: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Google Images\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# Find the search box\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "\n",
    "# Search for guitar images\n",
    "search_box.send_keys(value)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# initial all the list to store the product details\n",
    "product_url = []\n",
    "brand_list = []\n",
    "smartphone_name = []\n",
    "colour_list = []\n",
    "ram_list = []\n",
    "storage_rom_list = []\n",
    "primary_camera_list = []\n",
    "\n",
    "# fetch the product url\n",
    "urls = driver.find_elements(By.XPATH, '//a[@class=\"CGtC98\"]')\n",
    "for url in urls:\n",
    "    try:\n",
    "        # storing the url in list\n",
    "        product_url.append(url.get_attribute('href'))\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        product_url.append('-')\n",
    "        \n",
    "for i in product_url:\n",
    "    individual_page = driver.get(i)\n",
    "    try:    \n",
    "        # storing the name in list\n",
    "        name = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span')\n",
    "        \n",
    "        # Remove any leading/trailing hyphens\n",
    "        text = name.text.strip(\"-\")\n",
    "        brand_list.append(text)\n",
    "  \n",
    "        # Extract brand name (everything before first space)\n",
    "        brand_name = re.match(r\"^(.*?)\\s\", text).group(1)\n",
    "\n",
    "        # Separate product details from brand name\n",
    "        product_details = text.replace(brand_name + \" \", \"\")\n",
    "        \n",
    "        # Extract product name (everything before first opening parenthesis)\n",
    "        product_name = re.match(r\"^(.*?)\\(\", product_details).group(1)\n",
    "        \n",
    "        # Extract details within parentheses (separated by commas)\n",
    "        details_list = re.findall(r\"\\((.*?)\\)\", product_details)\n",
    "        \n",
    "        color = details_list[0].split(\",\")[0].strip()\n",
    "        colour_list.append(color)\n",
    "        \n",
    "        storage_ram = details_list[1].strip()\n",
    "\n",
    "        # Extract storage (assuming it's before RAM)\n",
    "        storage_match = re.match(r\"(.*?)\\s+GB\", storage_ram)\n",
    "        storage = storage_match.group(1) if storage_match else None  # Handle missing storage\n",
    "        storage_rom_list.append(storage)\n",
    "        \n",
    "        # Extract RAM\n",
    "        ram_match = re.search(r\"\\d+\\s+GB\\s+RAM\", storage_ram)\n",
    "        ram = ram_match.group(0).strip() if ram_match else None\n",
    "        \n",
    "        ram_list.append(ram)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        # If not found, append '-' to the list\n",
    "        brand_list.append('-')\n",
    "        \n",
    "# creating dic\n",
    "data = { \"Brand Name\": brand_name, \"Product Name\": product_name, \"Colour\": colour_list,\n",
    "        \"Storage(ROM)\": storage_rom_list,\n",
    "        \"RAM\": ram_list\n",
    "       }\n",
    "\n",
    "\n",
    "# creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('flipkart_product_detials.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb3d6e",
   "metadata": {},
   "source": [
    "### Q5 https://www.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d99377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the function to get the coordinates of input place.\n",
    "def get_coordinates(city_name):\n",
    "    \n",
    "    # initial WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        # Open Google Maps\n",
    "        driver.get(\"https://maps.google.com\")\n",
    "        \n",
    "        # Locate the search input field and enter the city name\n",
    "        search_element = driver.find_element(By.ID, \"searchboxinput\")\n",
    "        search_element.send_keys(city_name)\n",
    "        search_element.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Wait for search results to load\n",
    "        sleep(5)\n",
    "        \n",
    "        # Get the current URL\n",
    "        current_url = driver.current_url\n",
    "        \n",
    "        # Regular expression to find the pattern @latitude,longitude\n",
    "        match = re.search(r'@(-?\\d+\\.\\d+),(-?\\d+\\.\\d+)', url)\n",
    "        if match:\n",
    "            latitude, longitude = match.groups()\n",
    "            return float(latitude), float(longitude)\n",
    "        else:\n",
    "            return None, None\n",
    "    finally:\n",
    "        # Clean up\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "city_name = input('Enter your city name: ')\n",
    "latitude, longitude = get_coordinates(city_name)\n",
    "if latitude and longitude:\n",
    "    print(f\"Coordinates of {city_name}: Latitude = {latitude}, Longitude = {longitude}\")\n",
    "else:\n",
    "    print(f\"Failed to get coordinates for {city_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e3716",
   "metadata": {},
   "source": [
    "### Q6 https://www.digit.in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82cda312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize WebDriver and open the URL\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.digit.in/top-products/best-amd-gaming-laptops-with-nvidia-geforce-rtx-3050-4073.html\")\n",
    "\n",
    "# Fetch the elements\n",
    "laptop_details = driver.find_elements(By.XPATH, '//div[@class=\"rh_grid_image_3_col\"]')\n",
    "\n",
    "# Process each product detail\n",
    "laptop_specs = []\n",
    "for details in laptop_details:\n",
    "    separation = details.text.split('\\n')\n",
    "    laptop_name = separation[0]\n",
    "    \n",
    "    specs = { 'Name': laptop_name, 'Operating System': '', 'Display Size': '', 'Resolution': '', 'Processor': '' }\n",
    "    \n",
    "    for i in range(1, len(separation), 2):\n",
    "        spec_name = separation[i].strip().replace(\" :\", \"\")\n",
    "        spec_value = separation[i + 1].strip()\n",
    "        if 'Operating System' in spec_name:\n",
    "            specs['Operating System'] = spec_value\n",
    "        elif 'Display Size' in spec_name:\n",
    "            specs['Display Size'] = spec_value\n",
    "        elif 'Resolution' in spec_name:\n",
    "            specs['Resolution'] = spec_value\n",
    "        elif 'Processor' in spec_name:\n",
    "            specs['Processor'] = spec_value\n",
    "#     \n",
    "    laptop_specs.append(specs)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(laptop_specs)\n",
    "\n",
    "# Reset the index to create a Serial Number column\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'S.No'}, inplace=True)\n",
    "df['S.No'] += 1  # Make the index 1-based\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('best_gaming_laptops.csv', index=False)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cf474",
   "metadata": {},
   "source": [
    "### Q7 https://www.forbes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7778aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver (make sure to specify the path to your WebDriver if it's not in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Forbes billionaires page\n",
    "driver.get(\"https://www.forbes.com/billionaires/\")\n",
    "\n",
    "# Wait for the page to load\n",
    "sleep(5)\n",
    "\n",
    "# Initialize a list to store billionaire details\n",
    "billionaires = []\n",
    "\n",
    "# Get all the rows in the table (excluding the header row)\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, '[role=\"row\"]:not([role=\"rowheader\"])')\n",
    "\n",
    "# Loop through each row\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.CSS_SELECTOR, 'div[role=\"cell\"]')\n",
    "    if len(cells) > 0:\n",
    "        rank = cells[0].text\n",
    "        name = cells[1].text\n",
    "        net_worth = cells[2].text\n",
    "        age = cells[3].text\n",
    "        billionaires.append({\n",
    "                \"Rank\": rank,\n",
    "                \"Name\": name,\n",
    "                \"Net worth\": net_worth,\n",
    "                \"Age\": age,\n",
    "                \"Citizenship\": '-',\n",
    "                \"Source\": '-',\n",
    "                \"Industry\": '-'\n",
    "            })\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(billionaires)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('billionaires.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669cd115",
   "metadata": {},
   "source": [
    "### Q8  https://www.youtube.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "79ff9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube video page\n",
    "video_url = \"https://youtu.be/sQGvNPX8wmU?si=DQvqwZGgWZI-Xs_6\"\n",
    "driver.get(video_url)\n",
    "\n",
    "# Wait for the comments section to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.TAG_NAME, \"ytd-comments\")))\n",
    "\n",
    "# Scroll down to load comments\n",
    "def scroll_down():\n",
    "    driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "    sleep(2)\n",
    "\n",
    "# Initialize a list to store comments\n",
    "comments_data = []\n",
    "\n",
    "# Initialize the previous scroll height\n",
    "last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "# Loop to gather comments\n",
    "while len(comments_data) < 500:\n",
    "    comments = driver.find_elements(By.XPATH, '//*[@id=\"contents\"]/ytd-comment-thread-renderer')\n",
    "    scroll_down()\n",
    "    for comment in comments[len(comments_data):]:\n",
    "        content = comment.find_element(By.ID, \"content-text\").text\n",
    "        upvotes = comment.find_element(By.ID, \"vote-count-middle\").text\n",
    "        timestamp = comment.find_element(By.ID, 'published-time-text').text\n",
    "        comments_data.append({\n",
    "            \"Comment\": content,\n",
    "            \"Upvotes\": upvotes,\n",
    "            \"Time\": timestamp\n",
    "        })\n",
    "    \n",
    "    # Check the new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    if new_height == last_height:\n",
    "        break  # Break the loop if the scroll height has not changed\n",
    "    last_height = new_height\n",
    "    \n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('youtube_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553560a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
